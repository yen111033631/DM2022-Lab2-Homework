{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c63f836",
   "metadata": {},
   "source": [
    "# 1. Data preparation\n",
    "Transfer data from .json to .csv and seperate training data and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42a8a866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "if ('train_df.csv' not in os.listdir('../kaggle_data')) or ('test_df.csv' not in os.listdir('../kaggle_data')):\n",
    "    print(\"no file\")\n",
    "\n",
    "    data_id = pd.read_csv(\"../kaggle_data/data_identification.csv\")\n",
    "    emotion = pd.read_csv(\"../kaggle_data/emotion.csv\")\n",
    "    raw_df = pd.read_json(\"../kaggle_data/tweets_DM.json\", lines=True, orient='columns')\n",
    "\n",
    "    total_df = pd.json_normalize(raw_df._source)\n",
    "    total_df = total_df.rename(columns={\"tweet.tweet_id\":\"tweet_id\", \"tweet.hashtags\":\"hashtags\", \"tweet.text\":\"text\"}\n",
    "                              ).merge(data_id, on=\"tweet_id\", how=\"left\")\n",
    "    total_df.to_csv('../kaggle_data/total_df.csv',index=False)\n",
    "\n",
    "    train_df = total_df[total_df[\"identification\"] == \"train\"]\n",
    "    train_df = train_df.merge(emotion, on=\"tweet_id\", how=\"left\")\n",
    "    test_df = total_df[total_df[\"identification\"] == \"test\"]\n",
    "\n",
    "    train_df.to_csv('../kaggle_data/train_df.csv',index=False)\n",
    "    test_df.to_csv('../kaggle_data/test_df.csv',index=False) \n",
    "\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16daad56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24a97ab3",
   "metadata": {},
   "source": [
    "Read training data and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8372408",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../kaggle_data/train_df.csv\", lineterminator=\"\\n\")\n",
    "test_df = pd.read_csv(\"../kaggle_data/test_df.csv\", lineterminator=\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f62d54cb",
   "metadata": {},
   "source": [
    "remove special characters, ex: \"#\", \"@\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f57f36d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtags</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>identification</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['Snapchat']</td>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \"add me on Snapchat\" must be d...</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['freepress', 'TrumpLegacy', 'CNN']</td>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>brianklaas As we see, Trump is dangerous to fr...</td>\n",
       "      <td>train</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚ &lt;LH&gt;</td>\n",
       "      <td>train</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['authentic', 'LaughOutLoud']</td>\n",
       "      <td>0x1d755c</td>\n",
       "      <td>RISKshow TheKevinAllison Thx for the BEST TIME...</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x2c91a8</td>\n",
       "      <td>Still waiting on those supplies Liscus. &lt;LH&gt;</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              hashtags  tweet_id  \\\n",
       "0                         ['Snapchat']  0x376b20   \n",
       "1  ['freepress', 'TrumpLegacy', 'CNN']  0x2d5350   \n",
       "2                                   []  0x1cd5b0   \n",
       "3        ['authentic', 'LaughOutLoud']  0x1d755c   \n",
       "4                                   []  0x2c91a8   \n",
       "\n",
       "                                                text identification  \\\n",
       "0  People who post \"add me on Snapchat\" must be d...          train   \n",
       "1  brianklaas As we see, Trump is dangerous to fr...          train   \n",
       "2                Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚ <LH>          train   \n",
       "3  RISKshow TheKevinAllison Thx for the BEST TIME...          train   \n",
       "4       Still waiting on those supplies Liscus. <LH>          train   \n",
       "\n",
       "        emotion  \n",
       "0  anticipation  \n",
       "1       sadness  \n",
       "2          fear  \n",
       "3           joy  \n",
       "4  anticipation  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove special chars that will affect results\n",
    "# total_df['text'] = total_df['text'].str.replace(' ', '')\n",
    "train_df['text'] = train_df['text'].str.replace('#', '').str.replace('@', '')\n",
    "test_df['text'] = test_df['text'].str.replace('#', '').str.replace('@', '')\n",
    "train_df.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e1befdd",
   "metadata": {},
   "source": [
    "cause i don't have the right answers of test data, i seperate the training data into training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22afc8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "percent = 0.9\n",
    "train_df = train_df.sample(frac=1)\n",
    "T_len = round(train_df.shape[0] * percent)\n",
    "Train_df = train_df[:T_len]\n",
    "val_df = train_df[T_len:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "723090d1",
   "metadata": {},
   "source": [
    "# 2. Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d5530d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer(preserve_case=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "37dc4303",
   "metadata": {},
   "source": [
    "I choose tfidf vectorizer and the tweet tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "006316ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neaf2070/code/env/DM_new/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:524: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# BOW_500 = CountVectorizer(max_features=10, tokenizer=nltk.word_tokenize) \n",
    "Tfidf_10000 = TfidfVectorizer(max_features=10000, stop_words='english', tokenizer=tknzr.tokenize)\n",
    "Tfidf_10000.fit(train_df['text'])\n",
    "\n",
    "X_train = Tfidf_10000.transform(Train_df['text'])\n",
    "y_train = Train_df['emotion']\n",
    "X_val = Tfidf_10000.transform(val_df['text'])\n",
    "y_val = val_df['emotion']\n",
    "X_test = Tfidf_10000.transform(test_df['text'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "436e5a16",
   "metadata": {},
   "source": [
    "# 3. Model and Results Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d272ded8",
   "metadata": {},
   "source": [
    "Choose rogistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8744e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neaf2070/code/env/DM_new/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing, linear_model\n",
    "LR_model = linear_model.LogisticRegression()\n",
    "\n",
    "y_train = Train_df['emotion']\n",
    "## training!\n",
    "LR_model = LR_model.fit(X_train, y_train)\n",
    "\n",
    "## predict!\n",
    "y_train_pred = LR_model.predict(X_train)\n",
    "y_val_pred = LR_model.predict(X_val)\n",
    "y_test_pred = LR_model.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7f319cd",
   "metadata": {},
   "source": [
    "check the accuracy of training data and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7be0c2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.540437\n",
      "val accuracy: 0.536\n"
     ]
    }
   ],
   "source": [
    "## accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc_train = accuracy_score(y_true=y_train, y_pred=y_train_pred)\n",
    "acc_val = accuracy_score(y_true=y_val, y_pred=y_val_pred)\n",
    "\n",
    "print('training accuracy: {}'.format(round(acc_train, 6)))\n",
    "print('val accuracy: {}'.format(round(acc_val, 6)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e89504bf",
   "metadata": {},
   "source": [
    "---\n",
    "this is another model, but the performance is worse than LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da7323d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## build MultinomialNB model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "NB_model = MultinomialNB()\n",
    "\n",
    "## training!\n",
    "NB_model = NB_model.fit(X_train, y_train)\n",
    "\n",
    "## predict!\n",
    "y_train_pred = NB_model.predict(X_train)\n",
    "y_val_pred = NB_model.predict(X_val)\n",
    "y_test_pred = NB_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc6d932f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['anticipation', 'disgust', 'disgust', 'anticipation',\n",
       "       'anticipation', 'sadness', 'sadness', 'joy', 'joy', 'joy'],\n",
       "      dtype='<U12')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## build MultinomialNB model\n",
    "NB_model = MultinomialNB()\n",
    "\n",
    "## training!\n",
    "NB_model = NB_model.fit(X_train, y_train)\n",
    "\n",
    "## predict!\n",
    "y_train_pred = NB_model.predict(X_train)\n",
    "y_test_pred = NB_model.predict(X_test)\n",
    "\n",
    "## so we get the pred result\n",
    "y_test_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9757bec7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A9yx3tv-YTpo",
    "outputId": "0b1e4f04-d7a5-4e0d-8351-66c2b802cc42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.44736\n"
     ]
    }
   ],
   "source": [
    "## accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc_train = accuracy_score(y_true=y_train, y_pred=y_train_pred)\n",
    "# acc_test = accuracy_score(y_true=y_test, y_pred=y_test_pred)\n",
    "\n",
    "print('training accuracy: {}'.format(round(acc_train, 5)))\n",
    "# print('testing accuracy: {}'.format(round(acc_test, 2)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92da51c8",
   "metadata": {},
   "source": [
    "# 4. Save the result \n",
    "save the predicted label to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b16cd220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x28b412</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2de201</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x218443</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2939d5</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x26289a</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id       emotion\n",
       "0  0x28b412  anticipation\n",
       "1  0x2de201  anticipation\n",
       "2  0x218443       disgust\n",
       "3  0x2939d5           joy\n",
       "4  0x26289a  anticipation"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy = pd.DataFrame(y_test_pred)\n",
    "output_test = pd.concat([test_df.tweet_id, yy], axis=1)\n",
    "output_test = output_test.rename(columns={\"tweet_id\":\"id\", 0:\"emotion\"})\n",
    "output_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37ea3338",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_test.to_csv('../kaggle_data/output_test54_tweet_to_10000_tfidf_logic.csv',index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f281962e",
   "metadata": {},
   "source": [
    "# 5. Conclusion\n",
    "\n",
    "1. The dataset is so big that I have to transfer it to a proper file type, in order to reuse it again. \n",
    "2. I choose the set of TF-IDF vectorizer and the tweet tokenizer because the result is much better than the set of BOW vectorizer and normal tokenizer. \n",
    "3. The performance of the logic regression model is better than the Naive Bayes model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov  2 2022, 18:53:38) [GCC 11.3.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "f36c87c08ac7b4cef3146e542efbdcb42b218c33d16bda731019871ccd2cbb0c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
